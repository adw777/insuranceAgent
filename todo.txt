pdfs -> parse -> mds -> chunk[:1024] -> extract_keywords_from_chunks [intelligently using LLM or prolog?] -> {chunk + keywords} = payload

payload + chunk_embeddings -> qdrant_collection 
or
chunk_embeddings ->  qdrant_chunk_collection && keyword_embeddings -> qdrant_keyword_collection
have a primary key (common) between both collections


two flows:

1. Insurance Agent:
user_query -> enhance_user_query(using a smaller model) -> generate_embeddings_for_enhanced_query -> 
seach_for_top_k_similar_chunks_in_chunk_collection -> use_top_k_chunks + user_query with gemini 2.5 pro (solid prompt) -> 
response
try using continous chat with history management for this agent!


2. Recommender system for recommending best policy accoording to the user_info





for parsing policies:

{
    "company_name": "hdfc" or "lic",
    "type": "health" or "motor" or "insurance plans" or "pension plans",  
    "sub_type" : "if exist: "endowment plans" or "whole life plans",
    "title": "title_of_the_pdf",
    "pdf_link": ".pdf"
}



embedding generation:

{
    "company_name": "hdfc" or "lic",
    "type": "health" or "motor" or "insurance plans" or "pension plans",  
    "sub_type" : "if exist: "endowment plans" or "whole life plans",
    "title": "title_of_the_pdf",
    "pdf_link": ".pdf",
    "original_content": "parsed_pdf_in_markdown",
    "chunks": List of chunks for this pdf,
    "keywords": List of keywords for all the chunks in this doc
}

payload:
{
    "company_name": "hdfc" or "lic",
    "type": "health" or "motor" or "insurance plans" or "pension plans",  
    "sub_type" : "if exist: "endowment plans" or "whole life plans",
    "title": "title_of_the_pdf",
    "pdf_link": ".pdf",
    "chunk": "one chunk"
    "keywords": list of keywords for that chunk
} 
with chunk embeddings in policy_chunk
with keyword embeddings in policy_keyword






two flows to be added:

> from a a dict user_info (keywords) -> generate embeddings for all these keywords -> search for most similar chunks in policy_keyword collection -> get_chunks -> get_the_actual_policy_urls_from_mongo_for_those_chunks [remove duplicates] (this could also be just retrieved from qdrant payload)
endpoint will take user_info dict as input, and return the payload for the docs!

> from a list of user_info + preferences -> generate a query -> generate embeddings for the query -> search for the most similar top k chunks in "policy_chunks2" collection in qdrant -> re-rank the retrieved policies using gemini model for better relevancy with the user_info & preferences; returns top_n policies

> once we get the recommended policies -> get the "parsed_content" for those urls from mongo for each policy -> and pass parsed_content to gemini model -> and give a list of pre-generated synthetic situations -> and model will figure out whether this/that is covered in the policy or not (basically help the user identify in what-what strage circumstances they will get the policy or not)





select_policy_chat -> chat with one doc and answer user questions regarding it!
updates: make it chat with topK insurance policies (recommended) simultaneously and help user select the best out of these top_K
also append initial user_info in model context

here this update is not required actually as this endpoint will take in url of the pdf as input and then u can chat with that policy... so user can actually select from the frontend which pdf he wants to chat with, and that url for that pdf will input this endpoint - and then change the pdf after one is done!

once one policy is selected and finalised from select_policy_chat->
next: generate random hypothetical scenarios (pre generated ones and also could be input from the user)
now model will take these scenarios and policy content + user info and tell whether these scenarios r covered in the policy or not! 

policy_analyzer -> takes pdf_url -> analyzes policy for multiple scenarios -> returns a detailed report of whats included and whats not in the selected policy!


streamlit_app -> tabs for different endpoints
/chat : recommenation via chat 
/recommend-policies : user fills out a form (gives crucial info) and policies would be recommended
/chat-with-policy : when user gets recommended policies in both flows (chat or recommend-policies) for each policy user can click on that policy and chat with the policy using this endpoint (pdf_url for the selected policy will go as input for this endpoint); this will be like chat in the /chat endpoint
/policy-analyzer : this is also similar, but not in chat format. for a selected policy from the recommended policies from chat or recommend-policies, url of the selected policy will be the input and this returns a detailed analysis in markdown


a new endpoint chat-with-policy across all policies that have been recommended!

so via /chat we get 'n' policies recomended!
and via /recommend-policies too we get 'n' or 'm' policies recommended

now /chat-with-all-policies - will enable chatting with all the selected policies - so what we will do is 
take the urls of recommended policies and while answering the user queries - only search for those urls in qdrant in the pdf_link field and we will use it as a filter search - so for every user query we will get the most relevant top_k chunks only from those urls which have been recommended in either /chat or /recommend-policies  
and then get their chunk from the "chunk" field and use the chunks to answer the answer the qustion & respond to the user!

